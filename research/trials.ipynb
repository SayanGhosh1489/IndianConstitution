{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.document_loaders import PyPDFLoader, DirectoryLoader\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "import pinecone\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.llms import CTransformers\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_reader(Data):\n",
    "    \"\"\"\n",
    "    docment loader function.\n",
    "    package reeuire: from langchain.document_loaders import PyPDFLoader, DirectoryLoader\n",
    "    \"\"\"\n",
    "    loader = DirectoryLoader(Data,\n",
    "                    glob= '*.pdf',\n",
    "                    loader_cls= PyPDFLoader)\n",
    "    doc = loader.load()\n",
    "    return doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_text = data_reader(\"data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1431"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(extracted_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_split(extracted_data, size = 500, overlap = 50):\n",
    "    \"\"\"\n",
    "    Splitting the data into text chunks\n",
    "    default Chunk Size = 500, chunk_overlap = 50\n",
    "    Package required: from langchain.text_splitter import RecursiveCharacterTextSplitter \n",
    "    Returns: text_chunks\n",
    "    \"\"\"\n",
    "    text_spilter = RecursiveCharacterTextSplitter(chunk_size = size, chunk_overlap = overlap)\n",
    "    text_chunks = text_spilter.split_documents(extracted_data)\n",
    "    return text_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_chunk = text_split(extracted_data=extracted_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of chunks:  8269\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of chunks: \",len(text_chunk))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_embedding():\n",
    "    \"\"\"\n",
    "    Downloading embedding model from HuggingFace\n",
    "    Package required: from langchain.embeddings import HuggingFaceBgeEmbeddings\n",
    "    \"\"\"\n",
    "\n",
    "    embedding = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\", model_kwargs= {'device' : 'cpu'})\n",
    "    return embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = download_embedding()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#intializing pinecone and storing the data in vector DB\n",
    "load_dotenv()\n",
    "PINE_CONE_API = os.environ.get('PINE_CONE_API')\n",
    "index = os.environ.get('PINE_CONE_INDEX')\n",
    "\n",
    "os.environ['PINECONE_API_KEY'] = PINE_CONE_API\n",
    "index = index\n",
    "docsearch = PineconeVectorStore.from_texts([t.page_content for t in text_chunk], embedding=embedding, index_name = index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prompt_creator():\n",
    "    \"\"\"\n",
    "    Creating Prompt for the llm\n",
    "    Package Required: from langchain import PromptTemplate\n",
    "    return: dict\n",
    "    \"\"\"\n",
    "\n",
    "    prompt_template=\"\"\"\n",
    "    Use the following pieces of information to answer the user's question.\n",
    "    If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
    "\n",
    "    Context: {context}\n",
    "    Question: {question}\n",
    "\n",
    "    Only return the helpful answer below and nothing else.\n",
    "    Helpful answer:\n",
    "    \"\"\"\n",
    "    PROMPT=PromptTemplate(template=prompt_template, input_variables=[\"context\", \"question\"])\n",
    "    chain_type_kwargs={\"prompt\": PROMPT}\n",
    "    return chain_type_kwargs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = prompt_creator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm=CTransformers(model=\"Model/llama-2-7b-chat.ggmlv3.q8_0.bin\",\n",
    "                  model_type=\"llama\",\n",
    "                  config={'max_new_tokens':512,\n",
    "                          'temperature':0.8},device = 'gpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa=RetrievalQA.from_chain_type(\n",
    "    llm=llm, \n",
    "    chain_type=\"stuff\", \n",
    "    retriever=docsearch.as_retriever(search_kwargs={'k': 2}),\n",
    "    return_source_documents=True, \n",
    "    chain_type_kwargs=prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query :  what is lok sabha election\n",
      "\n",
      "Response :   Lok Sabha elections are held every five years to elect members of the Lok Sabha, which is the lower house of the Indian Parliament. The elections are conducted by the Election Commission of India, and voters cast their ballots for candidates representing various political parties or independents. The election is a direct poll, where people vote directly for their representatives in the Lok Sabha.\n",
      "\n",
      "source_documents :  [Document(page_content='of Houses and its  members. \\uf020\\n \\n\\uf0b7 Lok Sabha is also called House of people or Lower House, Rajya Sabha is also  \\ncalled as Upper House  or Council of  states. Lok Sabha represents  people of  \\nIndia as whole and Rajya Sabha represents  the States and Union territories. \\uf020\\n \\n\\uf0b7 After Rajya Sabha passes such resolution with absolute majority then resolution  \\nhas to be passed  by Lok Sabha  also (Article  67).\\uf020'), Document(page_content='Lok Sabha. Nicobar, Dadra  & \\n\\uf0b7 Addresses  Nagar Haveli and \\uf0b7 12 members of \\nParliament  Daman & Diu. the Rajya Sabha \\nafter general \\uf0b7 In case of from science, \\nelection and Puducherry,  literature, art  and \\n1st session of  President  can social service \\neach year.  make regulation  background.  \\nwhen Assembly  is \\uf0b7 Can nominate 2 \\nsuspended  or members to Lok \\ndissolved.  Sabha from the  \\nAnglo-Indian \\nCommunity.')]\n"
     ]
    }
   ],
   "source": [
    "user_input=input(f\"Input Prompt:\")\n",
    "result=qa({\"query\": user_input})\n",
    "print(\"query : \", result[\"query\"])\n",
    "print(\"\\nResponse : \", result[\"result\"])\n",
    "print(\"\\nsource_documents : \", result[\"source_documents\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "constitution",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
